{
    "provider": "openai",
    "model": "gpt-4.1",
    "duration": 8.14283800125122,
    "timestamp": "2025-10-24T12:52:00.298527",
    "parsed": {
        "folios": [
            {
                "folio": "",
                "text": "Gelüb im fronaltar die bůßend\nwir ganz vnd ein stück vor\ndem heiligen fron cruz. So\nlit ir vff ir brust vnd ein\nbein vff sant marien magdalene\nvinger vnd vff samstag nach\ndem oster tag. die do nach der\nander tag. daz abrelien. do\nfüeret wir gen messen. da\nlegent in fron altariu\nhebt sy ein hundert jar bůßend\nsie herschi do erstlich im einem\naltar. die pfarrin vnd\nsiet man noch bestendiglich\nim land und sich vnd die\nmagdalene als wündes sy\nDem sunentag früg do",
                "addition1": "Muren Glos",
                "addition2": "Gütten",
                "addition3": ""
            }
        ]
    },
    "text": "",
    "raw_response": {
        "id": "chatcmpl-CU9gezKadFWYivR5rRzN7rvH8s0kW",
        "model": "gpt-4.1-2025-04-14",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "message": {
                    "content": "{\n  \"folios\": [\n    {\n      \"folio\": \"\",\n      \"text\": \"Gelüb im fronaltar die bůßend\\nwir ganz vnd ein stück vor\\ndem heiligen fron cruz. So\\nlit ir vff ir brust vnd ein\\nbein vff sant marien magdalene\\nvinger vnd vff samstag nach\\ndem oster tag. die do nach der\\nander tag. daz abrelien. do\\nfüeret wir gen messen. da\\nlegent in fron altariu\\nhebt sy ein hundert jar bůßend\\nsie herschi do erstlich im einem\\naltar. die pfarrin vnd\\nsiet man noch bestendiglich\\nim land und sich vnd die\\nmagdalene als wündes sy\\nDem sunentag früg do\",\n      \"addition1\": \"Muren Glos\",\n      \"addition2\": \"Gütten\",\n      \"addition3\": \"\"\n    }\n  ]\n}",
                    "role": "assistant"
                }
            }
        ],
        "usage": {
            "prompt_tokens": 1429,
            "completion_tokens": 209,
            "total_tokens": 1638
        }
    },
    "usage": {
        "input_tokens": 1429,
        "output_tokens": 209,
        "total_tokens": 1638
    },
    "finish_reason": "stop"
}