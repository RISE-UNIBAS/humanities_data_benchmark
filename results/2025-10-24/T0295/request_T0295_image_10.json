{
    "provider": "mistral",
    "model": "mistral-medium-2508",
    "duration": 5.930939197540283,
    "timestamp": "2025-10-24T10:17:17.052046",
    "parsed": {
        "folios": [
            {
                "folio": "73",
                "text": "Jf zů dem erſten graff ſeinſgraf von albracht vo̊\n omgalt\nJf her ludwig landgraf von lůrſtenberg\nJf graff ſeſ von hermenberg\nJf graff Bernhart von ſegenſtein\nJf graff go̊tfred von haſenlod\nJf graff ſeinhart von Mamfeld\nJf graff ludwig von ſtuburg\nJf her ſoſtgraf von kleſſe beſpanchen\nJf her hanz von tůrgen\nJf her ſappenheim von ſtein wz vorhin genant\nJf huz von Roſenhan\nJf herg von waldenſtoff\nJf hylprand von thungen\nJf herg von ſtuben\nJf heinrich quaſt",
                "addition1": "",
                "addition2": "",
                "addition3": ""
            }
        ]
    },
    "text": "",
    "raw_response": {
        "id": "04fd50ff4c5142c0b50bde4ed38a6c46",
        "model": "mistral-medium-2508",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "message": {
                    "content": "{\n  \"folios\": [\n    {\n      \"folio\": \"73\",\n      \"text\": \"Jf zů dem erſten graff ſeinſgraf von albracht vo̊\\n omgalt\\nJf her ludwig landgraf von lůrſtenberg\\nJf graff ſeſ von hermenberg\\nJf graff Bernhart von ſegenſtein\\nJf graff go̊tfred von haſenlod\\nJf graff ſeinhart von Mamfeld\\nJf graff ludwig von ſtuburg\\nJf her ſoſtgraf von kleſſe beſpanchen\\nJf her hanz von tůrgen\\nJf her ſappenheim von ſtein wz vorhin genant\\nJf huz von Roſenhan\\nJf herg von waldenſtoff\\nJf hylprand von thungen\\nJf herg von ſtuben\\nJf heinrich quaſt\",\n      \"addition1\": \"\",\n      \"addition2\": \"\",\n      \"addition3\": \"\"\n    }\n  ]\n}",
                    "role": "assistant"
                }
            }
        ],
        "usage": {
            "prompt_tokens": 1703,
            "completion_tokens": 269,
            "total_tokens": 1972
        }
    },
    "usage": {
        "input_tokens": 1703,
        "output_tokens": 269,
        "total_tokens": 1972
    },
    "finish_reason": "stop"
}