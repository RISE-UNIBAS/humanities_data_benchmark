{
    "provider": "mistral",
    "model": "mistral-large-latest",
    "duration": 5.562952280044556,
    "timestamp": "2025-10-24T10:30:03.483949",
    "parsed": {
        "folios": [
            {
                "folio": "73",
                "text": "Jf zů dem erſten My he̊rſchgraff Albracht vo̊\nO̊ſterſreich\nJf her ludwig lantgraff von heſſenberg\nJf graff ſſ von hermenberg\nJf graff Bernhart von ſegen\nJf graff go̊tffried von haſſenlod\nJf graff ſchahert von Mamfeld\nJf graff ludwig von ſtuburg\nJf her ſoftſchalk von kleſſe beſpannch\nJf her hans von tůrgen\nJf her ſappem von Bappenheim\nJf her ſuppem von ſtein wſ vorhin Ritter\nJf huz von Roſenhan\nJf herg von waldenſtett\nJf hulpbrand von thungen\nJf herg von ſtuben\nJf he̊rin quaſt",
                "addition1": "",
                "addition2": "",
                "addition3": ""
            }
        ]
    },
    "text": "",
    "raw_response": {
        "id": "075f7819847349f0a5c47a92a7e4c679",
        "model": "mistral-large-latest",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "message": {
                    "content": "{\n  \"folios\": [\n    {\n      \"folio\": \"73\",\n      \"text\": \"Jf zů dem erſten My he̊rſchgraff Albracht vo̊\\nO̊ſterſreich\\nJf her ludwig lantgraff von heſſenberg\\nJf graff ſſ von hermenberg\\nJf graff Bernhart von ſegen\\nJf graff go̊tffried von haſſenlod\\nJf graff ſchahert von Mamfeld\\nJf graff ludwig von ſtuburg\\nJf her ſoftſchalk von kleſſe beſpannch\\nJf her hans von tůrgen\\nJf her ſappem von Bappenheim\\nJf her ſuppem von ſtein wſ vorhin Ritter\\nJf huz von Roſenhan\\nJf herg von waldenſtett\\nJf hulpbrand von thungen\\nJf herg von ſtuben\\nJf he̊rin quaſt\",\n      \"addition1\": \"\",\n      \"addition2\": \"\",\n      \"addition3\": \"\"\n    }\n  ]\n}",
                    "role": "assistant"
                }
            }
        ],
        "usage": {
            "prompt_tokens": 1703,
            "completion_tokens": 290,
            "total_tokens": 1993
        }
    },
    "usage": {
        "input_tokens": 1703,
        "output_tokens": 290,
        "total_tokens": 1993
    },
    "finish_reason": "stop"
}