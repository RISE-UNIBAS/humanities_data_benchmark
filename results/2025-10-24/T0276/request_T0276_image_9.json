{
    "provider": "openai",
    "model": "gpt-4o-mini",
    "duration": 5.378573179244995,
    "timestamp": "2025-10-24T10:24:01.733032",
    "parsed": {
        "folios": [
            {
                "folio": "",
                "text": "Von den erdgewaltigen Doß\n da zent man und die gläube\n in dem hertigen Doß. Der\n ist hert und goupt die de\n legende. Jn der wüsten\n dörfer ein kunig und zwey\n tüfften goupt, das mit bleichig\n war, das stant on der wüsten\n. Vnd der vey zeig das die\n nuzung. Das stant der\n wüsten, das stant das jn\n der wüsten, das stant das jn\n der wüsten. Das stant das jn\n der wüsten, das stant das jn\n der wüsten, das stant das jn\n der wüsten. Das stant das jn\n der wüsten, das stant das jn\n der wüsten.",
                "addition1": "In der grauen",
                "addition2": "der hertigen",
                "addition3": ""
            }
        ]
    },
    "text": "",
    "raw_response": {
        "id": "chatcmpl-CU7NT53ycJ1QmLw40PbdJvP5vikrw",
        "model": "gpt-4o-mini-2024-07-18",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "message": {
                    "content": "{\n  \"folios\": [\n    {\n      \"folio\": \"\",\n      \"text\": \"Von den erdgewaltigen Doß\\n da zent man und die gläube\\n in dem hertigen Doß. Der\\n ist hert und goupt die de\\n legende. Jn der wüsten\\n dörfer ein kunig und zwey\\n tüfften goupt, das mit bleichig\\n war, das stant on der wüsten\\n. Vnd der vey zeig das die\\n nuzung. Das stant der\\n wüsten, das stant das jn\\n der wüsten, das stant das jn\\n der wüsten. Das stant das jn\\n der wüsten, das stant das jn\\n der wüsten, das stant das jn\\n der wüsten. Das stant das jn\\n der wüsten, das stant das jn\\n der wüsten.\",\n      \"addition1\": \"In der grauen\",\n      \"addition2\": \"der hertigen\",\n      \"addition3\": \"\"\n    }\n  ]\n}",
                    "role": "assistant"
                }
            }
        ],
        "usage": {
            "prompt_tokens": 26165,
            "completion_tokens": 241,
            "total_tokens": 26406
        }
    },
    "usage": {
        "input_tokens": 26165,
        "output_tokens": 241,
        "total_tokens": 26406
    },
    "finish_reason": "stop"
}