{
    "provider": "openai",
    "model": "gpt-4o-mini",
    "duration": 5.841010093688965,
    "timestamp": "2025-10-24T10:22:59.428222",
    "parsed": {
        "folios": [
            {
                "folio": "73",
                "text": "Jeſt zō dem eſten Miſt beid gross alſo ſtaht vo\nanſat\nJeſt der hert hāding von graſp von huſtenberg\nJeſt der künig von ſt. gallenberg\nJeſt der graff Bechland von Loſtenſtein\nJeſt der graff ſtifſt von haſſelbad\nJeſt der graff ludwig von ſpeyer\nJeſt der gottſtall von ſt. paulen\nJeſt der hert von ſt. ungarn\nJeſt der hert von ſt. baſſen\nJeſt der hert von Rotenſt\nJeſt der graff von waldenſt\nJeſt der hert von thüngen\nJeſt der graff von ſtaden\nJeſt der hert von quāt",
                "addition1": "",
                "addition2": "",
                "addition3": ""
            }
        ]
    },
    "text": "",
    "raw_response": {
        "id": "chatcmpl-CU7MTHOIb1KlN70xP8FrZ2qaMofkm",
        "model": "gpt-4o-mini-2024-07-18",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "message": {
                    "content": "{\n  \"folios\": [\n    {\n      \"folio\": \"73\",\n      \"text\": \"Jeſt zō dem eſten Miſt beid gross alſo ſtaht vo\\nanſat\\nJeſt der hert hāding von graſp von huſtenberg\\nJeſt der künig von ſt. gallenberg\\nJeſt der graff Bechland von Loſtenſtein\\nJeſt der graff ſtifſt von haſſelbad\\nJeſt der graff ludwig von ſpeyer\\nJeſt der gottſtall von ſt. paulen\\nJeſt der hert von ſt. ungarn\\nJeſt der hert von ſt. baſſen\\nJeſt der hert von Rotenſt\\nJeſt der graff von waldenſt\\nJeſt der hert von thüngen\\nJeſt der graff von ſtaden\\nJeſt der hert von quāt\",\n      \"addition1\": \"\",\n      \"addition2\": \"\",\n      \"addition3\": \"\"\n    }\n  ]\n}",
                    "role": "assistant"
                }
            }
        ],
        "usage": {
            "prompt_tokens": 26165,
            "completion_tokens": 259,
            "total_tokens": 26424
        }
    },
    "usage": {
        "input_tokens": 26165,
        "output_tokens": 259,
        "total_tokens": 26424
    },
    "finish_reason": "stop"
}