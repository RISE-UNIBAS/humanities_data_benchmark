# This CITATION.cff file was generated with cffinit.
# Visit https://bit.ly/cffinit to generate yours today!

cff-version: 1.2.0
title: RISE-UNIBAS/humanities_data_benchmark
message: >-
  If you use this software, please cite it using the
  metadata from this file.
type: software
authors:
  - family-names: Hindermann
    given-names: Maximilian
    orcid: 'https://orcid.org/0000-0002-9337-4655'
  - given-names: Sorin
    family-names: Marti
    orcid: 'https://orcid.org/0000-0002-9541-1202'
  - given-names: Ina
    family-names: Serif
    orcid: 'https://orcid.org/0000-0003-2419-4252'
  - given-names: Sven
    family-names: Burkhardt
    orcid: 'https://orcid.org/0009-0001-4954-4426'
  - given-names: Gabriel
    family-names: MÃ¼ller
    orcid: 'https://orcid.org/0000-0001-8320-5148'
identifiers:
  - type: doi
    value: 10.5281/zenodo.16941752
    description: All versions
  - type: doi
    value: 10.5281/zenodo.16941753
    description: 'Version v0.1.0 '
  - type: doi
    value: 10.5281/zenodo.17010690
    description: 'Version v0.2.0 '
url: 'https://rise-unibas.github.io/humanities_data_benchmark/'
abstract: >-
  This repository contains benchmark datasets (images),
  prompts, ground truths, and evaluation scripts for
  assessing the performance of large language models (LLMs)
  on humanities-related tasks. The suite is designed as a
  resource for researchers and practitioners interested in
  systematically evaluating how well various LLMs perform on
  digital humanities (DH) tasks involving visual materials.
  For detailed test results and model comparisons, visit our
  results dashboard at
  https://rise-unibas.github.io/humanities_data_benchmark/.
keywords:
  - benchmark
  - LLM
  - digital humanities
license: GPL-3.0
version: 0.2.0
date-released: '2025-08-25'
